sure. I just want to know what a proper procedure for things like that
Swafford, Mike [11:46 AM]:
You can just kill it if it's a w3wp and it looks like things are getting out of hand.
Swafford, Mike [11:46 AM]:
if it's PLSQL Developer or something else, then we can't kill it without asking because 
it might be the prodution support group doing data fixes.
Swafford, Mike [11:47 AM]:
But basically, if it's a w3wp process that's hanging out there more than 30 minutes or so, 
the web session that kicked it off is long-gone and it's never going to get committed anyway.

If DBA kills w3wp session let FYI to Justin

##############################################################################################################################################
Also we had situation with 300 LOCKS and just killed some old ones first or if blocker indentified kill them first. Kill one
next one becomes the blocker. Wait 10 min and kill next one. Most we had to kill 3 blockers and it clear on it's own after

We had situation with 280 LOCKS again and this time we waited around 15 minutes and all web servers recycled and cleared locks. I guess
web servers restart automatically when they hit virtual memory limit or something.
I was able to capture sql from first blocker sessino: DELETE FROM S_SECURITY WHERE USER_ID = :Parm0
Mike will look into other logs to get more info if possible

12/01/08 -- Similar situation with 300 + blocking locks Mike had to kill all blockers to clear up this time

SELECT 
'ALTER SYSTEM KILL SESSION '' || sid || ',' || serial# || ''';' 
FROM 
v$session 
WHERE 
sid IN ( 
SELECT 
holding_session 
FROM 
dba_blockers 
); 

Most first blockers: UPDATE S_LEAVE L SET L.EST_DELIVERY_DATE = :B3, L.ACTUAL_DELIVERY_DATE = :B2, L.DISABILITY_DATE
= :B1 
WHERE L.LEAVE_ID = (
SELECT LEAVE_ID
FROM S_REQUEST 
WHERE REQUEST_ID = :B4 )

08

DELETE 
FROM S_SECURITY 
WHERE USER_ID = :Parm0



!!!! ALWAYS contact David Copasso or Steve Capson before kill bloker session attempt



##############################################################################################################################################
One more situation. We had 1 bloking lock for awile. I was able to identify blocker and kill it. However it did not clear blocking session. Then
Mike kill -9 process ID in UNIX. That did not remove blocker. I indetifed server and program for blocking session and ask ADA to shutdown application.
This remove blocking session. However we still had that session with KILLED status in Oracle. The only option is to bounce Oracle Database to remove it

Server: AETH\MVMPWKUTLAP11
Program: WKABJobController.exe

select session_id, mode_held from DBA_DML_LOCKS where session_id = 324

SESSION_ID	MODE_HELD
324	Row-X (SX) exclusive locks 
24	Row-S (SS) share locks 

324	Row-X (SX)
324	Row-S (SS)
324	Row-S (SS)
324	Row-X (SX)
324	Row-S (SS)
324	Row-S (SS)
324	Row-S (SS)
324	Row-X (SX)
324	Row-X (SX)
324	Row-X (SX)

Modes of Locking

Oracle uses two modes of locking in a multiuser database:
***Exclusive lock ***** mode prevents the associates resource from being shared.
This lock mode is obtained to modify data. The first transaction to lock a resource exclusively is the only transaction that
can alter the resource until the exclusive lock is released. 

***Share lock ***** mode allows the associated resource to be shared, depending on the operations involved.
Multiple users reading data can share the data, holding share locks to prevent concurrent access by a writer 
(who needs an exclusive lock). Several transactions can acquire share locks on the same resource. 


################################################################################################################################

11/25/2008
Got IM/call from Steve Capson and David Capasso on SPOK tickets someting causing white screen.

1. Look at sar and topas and see high CPU % utilization.
2. Run 

---Mike's who_active.sql
--I looked at it a different way. 
  Rather than looking at CPU, I was looking at waits. 
  I've attached --the SQL that I use to see the active queries in the database. 
  What I saw, was a bunch of queries --with the same hash all waiting on latches. 
  Knowing that processes spin on latches, I figured those --were the ones using the CPU. 
  The first time it happened, I also used nmon to identify some spids --and tracked those back to the session through v$process.
--nmon t (top process)



select /*+ leading(s) */ decode(pxs.qcsid, null, s.sid, pxs.qcsid) as QCSID, 
       s.sid, 
       p.spid, 
       substr(decode(s.type, 'USER', s.username, 'BACKGROUND', 'ORA-' ||bg.name, s.username), 1, 15) as username, 
       substr(decode(aa.name, 'UNKNOWN', '--', aa.name ), 1, 15) as command,
       s.status,
       substr(s.osuser, 1, 15) as osuser, 
       substr(s.machine, 1, 30) as machine,
       substr(s.program, 1, 20) as program, 
       substr(s.module, 1, 15) as module,
       substr(s.action, 1, 15) as action,
       s.sql_hash_value,
       sw.event,
       s.lockwait,
       s.row_wait_obj#,
       s.row_wait_row#,
       to_char(s.logon_time, 'YYYY-MM-DD HH24:MI') as logon_time, 
       s.last_call_et,
       sio.block_gets,
       sio.consistent_gets,
       sio.physical_reads,
       sio.block_changes,
       sio.consistent_changes
from v$session s,
     v$process p,
     v$sess_io sio,
     v$px_session pxs,
     v$bgprocess bg,
     audit_actions aa,
     v$session_wait sw
where s.paddr = p.addr
  and s.sid = sio.sid
  and s.saddr = pxs.saddr (+)
  and s.command = aa.action
  and s.paddr = bg.paddr (+)
  and s.status = 'ACTIVE'
  and s.type <> 'BACKGROUND'
  and s.sid = sw.sid
order by sio.consistent_gets, s.username, decode(pxs.qcsid, null, s.sid, pxs.qcsid);


3. See if any latches happens in database

 select SID, USERNAME, machine,status from v$session where sid  
in (select sid from v$session_wait where event='latch free');
select * 
from v$session s where s.last_call_et > 600 and sid 
in (select sid from v$session_wait where event='latch free');

4. Kill session sql

  select 'alter system kill session ''' || sid || ',' || serial# || ''';' 
  from v$session where --username='WKAB10' and sql_hash_value=3651867244;

  or

  --select 'alter system kill session ''' || sid || ',' || serial# || ''';' last_call_et 
--from v$session s where s.last_call_et > 600 and sid 
--in (select sid from v$session_wait where event='latch free');



******************HOW TO KILL PILE UP OF BLOKING SESSION ******************************

--TO KILL PILE UP SESSIONS
--1. Login to aetnaprod
--2. cd /workability/home/oracle/Monitor/Sql
--3. sqlplus / as sysdba
--4. @blocking_locks.sql
--5. Optional vi kill_blockers.sql and (remove heading)
--6. @kill_blockers.sql


**************************Life after 11g Upgrade**************************
We had CPU almost 100% with following wait events

kksfbc child completion
library cache: mutex X
cursor: pin S

  Last 5 min or so we had CPU almost 100% with following events
  kksfbc child completion
library cache: mutex X
cursor: pin S
  It much better now
Swafford, Mike [9:55 AM]:

  something must have grabbed a library cache latch or something
  could be something running for the first time or something
  caused a recompile


  Mike were these errors this moring ORA-600 related to mute X or that was something else?
Swafford, Mike [9:21 AM]:
  must have been the mutex
  that was right when they cleared
  I think they got hung and spun until they timed out on the mutex and threw the Ora-600
Berman, Eugene [9:21 AM]:
  k
Swafford, Mike [9:22 AM]:
  there were also stil about 5 left out there afterwards that I killed
  (I filtered the ORA-28 yesterday)
Berman, Eugene [9:23 AM]:
  ok. thx
Swafford, Mike [9:23 AM]:
  they had all been waiting for over 900 seconds so the client side had timed out long before
  so no harm in killing them

  here's the query I used to generate the kill in case it's helpful later

   select 'alter system kill session ''' || sid ||  ',' ||serial#|| ''';' from v$session where sql_id='d5fk4s1n4rfwj' and last_call_et>600;

    select 'alter system kill session ''' || sid ||  ',' ||serial#|| ''';' from v$session where sql_id='8h6c002f02mmx' and last_call_et>600;




Just saw some other waits with these latches

latch: cache buffers chains

read by other session

Mike killed bunch

 Are these sql's order by related or it just like you said before something running for the first time?
Swafford, Mike [11:18 AM]:
  no.  Looks to me like the DataExtract process was contending with this particular piece of SQL somehow.  Like a "hot block" in memory.  
  DataExtract kicked off at 11am and finished like 11:10.  
  Since it finished and since I cleared out the processes that were stuck, we seem to be OK.


Sorry.  Spoke too soon.  DataExtract wasn't the culprit.  It's still running.
  What we saw with Planview was that there was a particular query that hit memory fairly hard and if something caused it to slow down so that multiple copies of it started contending for the same block in memory, they ended up in a train wreck which got worse.  So killing off all the running copies cleared the problem and things continued.
Berman, Eugene [11:23 AM]:
  Did it happen often after upgrade in Planview?
Swafford, Mike [11:23 AM]:
  it happened for the first day or so. 
  One thing about 11g is that it does some adaptive query plan stuff
  so that it looks at the supplied bind values over time and tries to adjust plans accordingly.
  So hopefully it will adjust some on it's own.  In the mean time, I'm going to do some AWR reports and see if I can see any performance tweaks we might be able to make.
  Might be we can do an index or two and get things settled down.
  I haven't heard any user complaints.
Berman, Eugene [11:26 AM]:
  Good idea
 DBconsole picked up that sql that you identified (8h6c002f02mmx) as  well during 11 AM CPU spike.
Swafford, Mike [11:53 AM]:
  aha
  so that was it
  I'll see what I can do with that sql


 latch: cache buffers chains

Mike created index it helped some but still see waits for  latch: cache buffers chains

SELECT * FROM ( SELECT ROWNUM R, LEAVE_ID, CONFIRMATION_NUMBER, 
PRODUCT, COMPANY_NAME, EMPLOYEE_ID, EMP_ID, LAST_NAME, FIRST_NAM
E, EMP_STATUS_CODE, TERMINATION_DATE FROM( SELECT /*+ no_index(s
_person T_PERSON_IDX_002) */ '' AS LEAVE_ID, '' AS CONFIRMATION_
NUMBER, '' AS PRODUCT, '' AS COMPANY_NAME, S_EMPLOYEE.EMPLOYEE_I
D, S_EMPLOYEE.EMP_ID, S_PERSON.LAST_NAME, S_PERSON.FIRST_NAME, D
ECODE(S_EMPLOYEE.EMP_STATUS_CODE,'T','Resigned','A','Active','I'
,'Inactive','L','Leave','R','Retired') AS EMP_STATUS_CODE, S_EMP
LOYEE.TERMINATION_DATE FROM S_EMPLOYEE,S_PERSON WHERE S_PERSON.P
ERSON_ID = S_EMPLOYEE.PERSON_ID AND GROUP_ID IN ( SELECT DISTINC
T GROUP_ID FROM S_GROUP G START WITH GROUP_ID IN ( SELECT DISTIN
CT S_GE.GROUP_ID FROM S_COMPANY_ROLE_MATRIX S_CRM, S_GROUP_EMPLO
YEE S_GE, S_COMPANY_ROLE S_CR WHERE S_GE.EMPLOYEE_ID = :B3 AND S
_GE.COMPANY_ID = (SELECT COMPANY_ID FROM S_EMPLOYEE WHERE EMPLOY
EE_ID = :B3 ) AND S_GE.ROLE_ID = S_CR.FILE_ROLE_CODE AND S_CR.CO
MPANY_ROLE_ID = S_CRM.COMPANY_ROLE_ID AND S_CR.PRIVILEGED_ROLE =
 'Y' AND S_CRM.TEAM_RIGHT_TYPES_ID = 302 ) AND G.COMPANY_ID = (S
ELECT COMPANY_ID FROM S_EMPLOYEE WHERE EMPLOYEE_ID = :B3 ) CONNE
CT BY PARENT_GROUP_ID = PRIOR GROUP_ID ) AND LAST_NAME LIKE :B2 
AND FIRST_NAME LIKE :B1 ORDER BY LAST_NAME, FIRST_NAME)) WHERE R
 >= :B5 AND R <= :B4


*************************************************************************

They updated SR with reference to this Note for DB Diagnostic: 61552.1

Based on all info. Here are the steps.

sqlplus -prelim / as sysdba
oradebug setmypid
oradebug unlimit;
oradebug dump systemstate 266
--wait about 1 min
oradebug dump systemstate 266
--wait about 1 min
oradebug dump systemstate 266
exit

Look for big trace file under: /workability/wkabprod/oracle/admin/diag/rdbms/wkabprod/wkabprod/trace




  here's the query I used to generate the kill in case it's helpful later

   
   --MUTE X sql
   spool killMuteX.sql
   select 'alter system kill session ''' || sid ||  ',' ||serial#|| ''';' from v$session where sql_id='d5fk4s1n4rfwj' and last_call_et>600;
   spool off;
   @killMuteX.sql

   --Bad Performance SQL
   spool killWaits.sql

   select 'alter system kill session ''' || sid ||  ',' ||serial#|| ''';' from v$session where sql_id='79wu104t47wn5' and last_call_et>600;
   select 'alter system kill session ''' || sid ||  ',' ||serial#|| ''';' from v$session where sql_id='8h6c002f02mmx';

79wu104t47wn5

   or

   select 'alter system kill session ''' || sid ||  ',' ||serial#|| ''';' from v$session where sql_id='dsk8mtp7z5jxc' and last_call_et>600;

   select 'alter system kill session ''' || sid ||  ',' ||serial#|| ''';' from v$session where sql_id='52cdd8xwsjbkc' and last_call_et>600;
      
   spool off;
   @killWaits.sql
   
 select 'alter system kill session ''' || sid ||  ',' ||serial#|| ''';' from v$session where sql_id='9k78cjaqtx77z' and last_call_et>500;

--TO KILL PILE UP SESSIONS
--1. Login to aetnaprod
--2. cd /workability/home/oracle/Monitor/Sql
--3. sqlplus / as sysdba
--4. @blocking_locks.sql
--5. Optional vi kill_blockers.sql and (remove heading)
--6. @kill_blockers.sql



   select  'PARAMETERS' as ROWFLAG,
                sum(case
                       when status='ACTIVE'
                        and program='w3wp.exe'
                        and last_call_et > 500
                       then 1
                       else 0
                    end
                   ) as long_running_queries,
                 sum(case
                       when status='ACTIVE'
                        and sql_id='d5fk4s1n4rfwj'
                        and last_call_et > 30
                       then 1
                       else 0
                    end
                   ) as long_mutex_query,
                sum(case
                       when status='ACTIVE'
                        and event='library cache: mutex X'
                        and last_call_et > 30
                       then 1
                       else 0
                    end) as sessions_waiting_on_mutex
     from v\$session s,
             audit_actions aa
    where s.command = aa.action
      and s.status = 'ACTIVE'
      and s.type <> 'BACKGROUND'
      and s.event not in ('jobq slave wait', 'rdbms ipc message')
      and s.event not like 'Streams AQ:%'
   /
   spool off
   EOF


***********************************************************************************

Location of who.logs on Aetnaprod: /workability/home/oracle/logs

Location of blocking logs on Aetnaprod: /workability/home/oracle/Monitor/Logs



***********************BLOCKING LOCK REASON **********************

Got some more detail on the root cause and the good news is that there's an easy remedy. 

With the cool ASH and ADR stuff now available now in 11g, I was able to track back to the first moments of the blocking and sort it out.

What's happening is that they're doing security maintenance cleaning up old users.  As part of it they issue...

DELETE FROM S_SECURITY WHERE USER_ID = :Parm0

There's a foreign key constraint between T_SECURITY(USER_ID) and T_LEAVE(OWNER_ID).
 As a result, it has to check to make sure that there are no rows in T_LEAVE that reference that row in T_SECURITY (to avoid creating an orphaned T_LEAVE row).
  However, there are no indexes on T_LEAVE that begin with OWNER_ID, so it has to take a shared lock on the whole T_LEAVE table to do the current read.  That would be OK, except that it has to wait for anyone else to let go of their locks on rows in T_LEAVE and while it waits, it blocks all the other people trying to update rows in T_LEAVE.  This is the only case in Oracle where a reader can block - that is when it's doing a referential integrity check.  

So, in Wednesday's case, they started cleaning up users, but there was a slow transaction that had locks on T_LEAVE that blocked the delete from T_SECURITY.  The delete then blocked everyone else trying to update T_LEAVE which caused the pile-up.

The nice thing is that there's a fairly simple solution for this.  Adding an index on T_LEAVE like:

create index wkab10.FK_SECURITY2LEAVE on wkab10.t_leave(owner_id) tablespace wkab_index;

This will allow Oracle to avoid the shared table lock and just do it's current reads via the index.  So it doesn't prevent the slow transaction on T_LEAVE, but it should prevent the pile-up.  I'll plan on including the index in my DBA suggestions for December release.

Mike


************************************************** Latest MuteX Issues

--waits
cursor: mutex X
cursor: mutex S
kksfbc child completion


SQL_TEXT
SELECT L."LOOKUP_ID", L."CODE_TYPE", L."CODE_VALUE", L."PARENT_I
D", L."DISPLAY_ORDER", L."DISPLAY_ENABLE", L."DISPLAY_VALUE", L.
"""KEY_ID"", L.""CREATE_DATE"", L.""EDIT_DATE"", L.""LONG_DESCRIPTION"" ,"
 L.DISPLAY_VALUE AS COMPANY_LOOKUP_DISPLAY_VALUE  FROM S_WKAB_LO
OKUP L WHERE  L.CODE_TYPE = :Parm0 AND L.DISPLAY_ENABLE = :"SYS_
B_0" ORDER BY L.DISPLAY_ORDER 


4164271223

It was clearing on it's own for some time. But at the end of the day it reached out number of connections


ORA-00020: maximum number of processes



ORA-600 internal error [kksfbc-5wrong-kkscsflgs] And Sessions Waiting on 'cursor: mutex s''
Note: 1067755.1

---->Mike flashed out share pool and kill inactive sessions. It took 5 min to get rid off sessions.

---->Mike Killes idle session that had been sitting there more then 900 seconds

ALTER SYSTEM FLUSH SHARED_POOL;
select 'alter system kill session ''' || sid || ',' || serial# || ''';' from v$session where event like '%from client%' and program='w3wp.exe' and last_call_et>900;
Mike had to kill PeopleSoft session 

--Run this it looks like helps to clear waits
exec dbms_stats.gather_table_stats(ownname=>'WKAB10', tabname=>'T_WKAB_LOOKUP', no_invalidate=>false, cascade=>true);




***************************************************************

I don't think you'll have to deal with this while I'm out, but just in case.  We've had a few of those runaways on wkabprod recently.  They seem to be more common on Mondays after things go quiet over the weekend and the plan falls out of cache.  Anyway, until they get the fix in for June we may see it.  So I sometimes check for them in the morning when I first log on so I can catch them early.  So while I'm out, you may want to run:
 
select count(*) from v$session where sql_id='42nmduqvvyu46' and last_call_et > 100;  
 
If this comes back with something non-zero, then there's probably an issue.  You can IM Steve Capson or Dave Capasso and get their OK to clear it up.  Then, to clear it up run:
 
exec dbms_stats.gather_index_stats(ownname=>'WKAB10', indname=>'TASK_INSTANCE_IDX2', no_invalidate=>FALSE, force=>true);
 
This is should keep you from getting new run-aways out there.  You'll then need to clean up the ones already running.  To do that, I use:

select 'alter system kill session ''' || sid || ',' || serial# || '''; ' from v$session where sql_id='42nmduqvvyu46' and last_call_et > 100;
 
The output from this is a list of kill statements that I then copy and past into another sqlplus window.
 
Things should then start to clear.


******* Tom suggestion on how to build kill.sql ******************

set echo off termout off feedback off verify off pagesize 0 trimspool on

whenever sqlerror exit failure;

spool kill.sql

select 'ALTER SYSTEM KILL SESSION '||chr(39)||sid||','||serial#||chr(39)||';'
FROM v$session
where ....
/

spool off

@kill.sql


